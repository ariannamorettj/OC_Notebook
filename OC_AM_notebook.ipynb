{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCitations Notebook\n",
    "### Arianna Moretti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### 2022\n",
    "\n",
    "1. [22/02 - 02/03 (Log Data Study)](#entry_1)\n",
    "2. [02/03 - 09/03 (OC Index Software Code Refactoring - NOCI + Mapping Merge)](#entry_2)\n",
    "3. [09/03 - 15/03 (Log Data Visualization d3.js)](#entry_3)\n",
    "4. [15/03 - 22/03 (????)](#entry_4)\n",
    "\n",
    "#### 202*\n",
    "\n",
    "5. [??/?? - ??/?? (????)](#entry_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22/02 - 02/03 (Log Data Study) <a class=\"anchor\" id=\"entry_1\"></a>\n",
    "\n",
    "### Studio Files di Log Raw\n",
    "\n",
    "<ul>\n",
    "    <li>Download cartella Dropbox con file di log raw per 2021</li>\n",
    "    <li>Studio dei dati statistici: <a href=\"https://github.com/opencitations/statistics/tree/master/script\">opencitations statistics repo </a> </li>\n",
    "    <li>Studio del file format Prometheus: <a href=\"https://sysdig.com/blog/prometheus-metrics/\"> https://sysdig.com/blog/prometheus-metrics/</a>, <a href=\"https://prometheus.io/docs/instrumenting/clientlibs/\"> https://prometheus.io/docs/instrumenting/clientlibs/</a>\n",
    "    <li>Esempio di <a href=\"http://opencitations.net/statistics/2022-01\">call API per i dati di Log di Gennaio 2021</a> </li>\n",
    "</ul>\n",
    "\n",
    "#### Prometheus File Format\n",
    "Prometheus is an open source time series database including a collection of client libraries which allow metrics to be published, so to be collected by the metrics server. The Prometheus metrics format is largely adopted and became also an independent project: OpenMetrics, aimed at making this metric format specification a standard. Sysdig Monitor dynamically detects and scrape Prometheus metrics.\n",
    "##### Custom Metrics\n",
    "Source: <a href=\"https://sysdig.com/blog/how-to-instrument-code-custom-metrics-vs-apm-vs-opentracing/\">href=\"https://sysdig.com/blog/how-to-instrument-code-custom-metrics-vs-apm-vs-opentracing/</a>\n",
    "Custom Metrics (JMX, Golang expvar, Prometheus, statsd...) is an approach on how to instrument code to easily monitor the performance and troubleshooting of an application. Typical aspects to be monitored are: the most visited components a web page, the slowest components to load, the difference of speed in loading the frontend and the backend, which factors affect the speed of the process (location, browser, device). The options to monitor those aspects are: using an APM instrument, using OpenTracing libraries, or generating metrics ad-hoc for specific components.\n",
    "\n",
    "##### Comparison between CM, APM and Opentracing\n",
    "\n",
    "|Issue | Custom Metrics | APM | Opentracing |\n",
    "| --- | --- | --- | --- |\n",
    "| Code-related problems | Devs need to provide metrics with performance in code but are not as easy to identify | Yes | Yes |\n",
    "| Infrastructure-related problems | Yes | No | No |\n",
    "| Node and service level aggregation | Yes | No | No |\n",
    "| Standard implementaton | Some languages include a standard way to implement them: (Prometheus, Java JMX, Go expvar, …) | No | Yes |\n",
    "| Allows capacity planning | Yes | No | No |\n",
    "| Allows complete statistical measurements | Yes | No | No |\n",
    "| Cloud Native Computing Foundation standard | Prometheus metrics only | No | Yes |\n",
    "| Distributed application analysis | Yes, without per trace analysis | Yes | Yes |\n",
    "| Useful for developers for pre-production environments | Yes | Yes | Yes |\n",
    "| Useful for complete DevOps strategy | Yes | No | No |\n",
    "\n",
    "##### Metrics notations: dot notation vs multi-dimensional tagged metrics\n",
    "Source: <a href=\"https://sysdig.com/blog/prometheus-metrics/\">https://sysdig.com/blog/prometheus-metrics/</a>\n",
    "For Python we need the third-party library Prometheu to feed the monitoring system.\n",
    "There are two main paradigms to represent a metric: <b>dot notation</b> and <b>multi-dimensional tagged metrics</b>.\n",
    "In a dot-notated metric, data are provided in dot-separated format in the name of the metric, which determine the detail and the hierarchy needed. The arrangement of the metric depends on the piece of information needed. \n",
    "In Prometheus metric format a flat approach is adopted to metrics naming. Instead of a hierarchical, dot separated name, there are names combined with a series of labels or tags. \"Highly dimensional data\" imply the possibility to associate any number of context-specific labels to every submitted metric.\n",
    "\n",
    "##### Prometheus metrics (OpenMetrics)\n",
    "Prometheus metrics format is line oriented: lines are separated by a line feed character (n), and the last line must end with a line feed character, while empty lines are somply ignored.\n",
    "\n",
    "A metric is composed by the (optional) components below:\n",
    "\n",
    "<ul>\n",
    "    <li>Metric name</li>\n",
    "    <li>Any number of labels (can be 0), represented as a key-value array</li>\n",
    "    <li>Current metric value</li>\n",
    "    <li>Optional metric timestamp</li>\n",
    "</ul>\n",
    "\n",
    "Metric output is typically preceded with **# HELP** and **# TYPE** metadata lines.\n",
    "The HELP string identifies the metric name and a brief description of it. The TYPE string identifies the type of metric. If there’s no TYPE before a metric, the metric is set to untyped. Everything else that starts with a # is parsed as a comment.\n",
    "\n",
    "(**continua*)\n",
    "\n",
    "##### Implement Prometheus custom metric instrumentation in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02/03 - 09/03 (OC Index Software Code Refactoring - NOCI + Mapping Merge) <a class=\"anchor\" id=\"entry_2\"></a>\n",
    "\n",
    "### NOCI material\n",
    "\n",
    "1. **OpenCitations Index espansion**\n",
    "\n",
    "   1.1 *ADDITIONS*\n",
    "    \n",
    "      1.1.1 [NIH citation source](#en_1.1.1)\n",
    "\n",
    "      1.1.2 [NOCI glob](#en_1.1.2)\n",
    "\n",
    "      1.1.3 [PMID manager](#en_1.1.3)\n",
    "\n",
    "      1.1.4 [NIH resource finder](#en_1.1.4)\n",
    "        \n",
    "   1.2 *ADJUSTMENTS / EXPANSIONS*\n",
    "    \n",
    "      1.2.1 [citation/oci.py](#en_1.2.1)\n",
    "        \n",
    "      1.2.2 [finder/resourcefinder.py](#en_1.2.2)\n",
    "        \n",
    "      1.2.3 [finder/dataciteresourcefinder.py](#en_1.2.3)\n",
    "      \n",
    "      1.2.4 [finder/crossrefresourcefinder.py](#en_1.2.4)\n",
    "      \n",
    "      1.2.5 [finder/orcidresourcefinder.py](#en_1.2.5)\n",
    "      \n",
    "      1.2.6 [storer/csvmanager.py](#en_1.2.6)\n",
    "      \n",
    "      1.2.7 [storer/datahandler.py](#en_1.2.7)\n",
    "      \n",
    "      1.2.8 [storer/update.py](#en_1.2.8)\n",
    "      \n",
    "      \n",
    "        \n",
    "2. **Ramose**\n",
    "\n",
    "    2.1 [NOCI configuration file](#en_2.1)\n",
    "    \n",
    "    2.2 [indexapi.py extension](#en_2.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 NIH citation source <a class=\"anchor\" id=\"en_1.1.1\"></a>\n",
    "\n",
    "Codice della citation source per il National Institute of Health. Il dataset citazionale (NIH-OCC) fornisce solo le informazioni minime richieste dall'OpenCitations data model, ovvero **citante** e **citato**, espressi rispettivamente nei campi \"citing\" e \"referenced\" del file CSV del NIH-OCC.\n",
    "Il codice è stato testato con successo. \n",
    "Di seguito, il codice del NIH citation source e del rispettivo test case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk, sep, remove\n",
    "from os.path import isdir\n",
    "from json import load\n",
    "from csv import DictWriter\n",
    "from index.citation.citationsource import CSVFileCitationSource\n",
    "from index.identifier.pmidmanager import PMIDManager\n",
    "from index.citation.oci import Citation, OCIManager\n",
    "\n",
    "\n",
    "class NIHCitationSource( CSVFileCitationSource ):\n",
    "    def __init__(self, src, local_name=\"\"):\n",
    "        self.pmid = PMIDManager()\n",
    "        super( NIHCitationSource, self ).__init__( src, local_name )\n",
    "\n",
    "    def get_next_citation_data(self):\n",
    "        row = self._get_next_in_file()\n",
    "        #id_type = OCIManager.pmid_type\n",
    "\n",
    "        while row is not None:\n",
    "            citing = self.pmid.normalise(row.get(\"citing\"))\n",
    "            cited = self.pmid.normalise(row.get(\"referenced\"))\n",
    "\n",
    "            self.update_status_file()\n",
    "            return citing, cited, None, None, None, None #, id_type\n",
    "            self.update_status_file()\n",
    "            row = self._get_next_in_file()\n",
    "\n",
    "        remove(self.status_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/10_noci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from index.coci.glob import process\n",
    "from os import sep, makedirs\n",
    "from os.path import exists\n",
    "from shutil import rmtree\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from index.noci.nationalinstituteofhealthsource import NIHCitationSource\n",
    "from csv import DictReader\n",
    "\n",
    "\n",
    "class NOCITest(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.input_file = \"index%stest_data%snih_dump%ssource.csv\" % (sep, sep, sep)\n",
    "        self.citations = \"index%stest_data%snih_dump%scitations.csv\" % (sep, sep, sep)\n",
    "\n",
    "    def test_citation_source(self):\n",
    "        ns = NIHCitationSource( self.input_file )\n",
    "        new = []\n",
    "        cit = ns.get_next_citation_data()\n",
    "        while cit is not None:\n",
    "            citing, cited, creation, timespan, journal_sc, author_sc = cit\n",
    "            new.append({\n",
    "                \"citing\": citing,\n",
    "                \"cited\": cited,\n",
    "                \"creation\": \"\" if creation is None else creation,\n",
    "                \"timespan\": \"\" if timespan is None else timespan,\n",
    "                \"journal_sc\": \"no\" if journal_sc is None else journal_sc,\n",
    "                \"author_sc\": \"no\" if author_sc is None else author_sc\n",
    "            })\n",
    "            cit = ns.get_next_citation_data()\n",
    "\n",
    "        with open(self.citations, encoding=\"utf8\") as f:\n",
    "            old = list(DictReader(f))\n",
    "\n",
    "        self.assertEqual(new, old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 NOCI glob <a class=\"anchor\" id=\"en_1.1.2\"></a>\n",
    "L' iCite Database contenente il NIH-OCC, ovvero la data source di NOCI, e un altro dataset: **iCite Metadata**. Se il NIH-OCC contiene solamente dati citazionali rappresentati dai PMID del citante e del citato, iCite Metadata contiene metadati relativi alle entità bibliografiche (identificate da PMID) coinvolte nelle citazioni contenute nel NIH-OCC. iCite Metadata contiene dunque delle informazioni che possono essere rielaborate al fine di ricavarne (direttamente o indirettamente) i metadati utili a completare i quattro campi della tupla a sei elementi non coperti dal NIH-OCC.\n",
    "Tra i campi del dataset iCite Metadata, **\"doi\"** fornisce l'informazione di **mapping** PMID-DOI. Questo dato è particolarmente utile perché permette di sfruttare i servizi API dei DOI per ricavare le informazioni che non vengono fornite né in iCite Metadata né nei servizi API dei PMIDs. \n",
    "I dati ricavati sono salvati in files CSV che vengono utilizzati come materiale di supporto nel processo di popolazione dell'Indice citazionale. \n",
    "Di seguito, il codice del glob di NOCI e il relativo test, passato con successo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from index.finder.crossrefresourcefinder import CrossrefResourceFinder\n",
    "from index.finder.orcidresourcefinder import ORCIDResourceFinder\n",
    "from index.identifier.pmidmanager import PMIDManager\n",
    "from index.identifier.doimanager import DOIManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from os import sep, makedirs, walk\n",
    "import os\n",
    "from os.path import exists\n",
    "import json\n",
    "from re import sub\n",
    "from index.citation.oci import Citation\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "import re\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def issn_data_recover(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf8') as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            types = type(journal_issn_dict)\n",
    "            return journal_issn_dict\n",
    "\n",
    "def issn_data_to_cache(name_issn_dict, directory):\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    with open(filename, 'w', encoding='utf-8' ) as fd:\n",
    "            json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "#PUB DATE EXTRACTION : takes in input a data structure representing a bibliographic entity\n",
    "def build_pubdate(row):\n",
    "    year = str(row[\"year\"])\n",
    "    str_year = sub( \"[^\\d]\", \"\", year)[:4]\n",
    "    if str_year:\n",
    "        return str_year\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# get_all_files extracts all the needed files from the input directory\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    opener = None\n",
    "\n",
    "    if i_dir.endswith( \".zip\" ):\n",
    "        zf = ZipFile( i_dir )\n",
    "        for name in zf.namelist():\n",
    "            if name.lower().endswith(\".csv\") and \"citations\" not in name.lower() and \"source\" not in name.lower():\n",
    "                result.append( name )\n",
    "        opener = zf.open\n",
    "    elif i_dir.endswith( \".tar.gz\" ):\n",
    "        tf = TarFile.open( i_dir )\n",
    "        for name in tf.getnames():\n",
    "            if name.lower().endswith(\".csv\") and \"citations\" not in name.lower() and \"source\" not in name.lower():\n",
    "                result.append(name)\n",
    "        opener = tf.extractfile\n",
    "\n",
    "    else:\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in cur_files:\n",
    "                if file.lower().endswith( \".csv\" ) and \"citations\" not in file.lower() and \"source\" not in file.lower():\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        opener = open\n",
    "    return result, opener\n",
    "\n",
    "\n",
    "def process(input_dir, output_dir, n):\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_pmid_with_no_date = set()\n",
    "    valid_pmid = CSVManager( output_dir + sep + \"valid_pmid.csv\" )\n",
    "    valid_doi = CSVManager(\"index/test_data/crossref_glob\" + sep + \"valid_doi.csv\")\n",
    "    id_date = CSVManager( output_dir + sep + \"id_date_pmid.csv\" )\n",
    "    id_issn = CSVManager( output_dir + sep + \"id_issn_pmid.csv\" )\n",
    "    id_orcid = CSVManager( output_dir + sep + \"id_orcid_pmid.csv\" )\n",
    "    journal_issn_dict = issn_data_recover(output_dir) #just an empty dict, in case of a code break\n",
    "    pmid_manager = PMIDManager(valid_pmid)\n",
    "    crossref_resource_finder = CrossrefResourceFinder(valid_doi)\n",
    "    orcid_resource_finder = ORCIDResourceFinder(valid_doi)\n",
    "\n",
    "    doi_manager = DOIManager(valid_doi)\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "\n",
    "    all_files, opener = get_all_files(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "\n",
    "    # Read all the CSV file in the NIH dump to create the main information of all the indexes\n",
    "    print( \"\\n\\n# Add valid PMIDs from NIH metadata\" )\n",
    "    for file_idx, file in enumerate( all_files, 1 ):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000 ):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna(\"\", inplace=True)\n",
    "\n",
    "            print( \"Open file %s of %s\" % (file_idx, len_all_files) )\n",
    "            for index, row in f.iterrows():\n",
    "                if int(index) !=0 and int(index) % int(n) == 0:\n",
    "                    print( \"Group nr.\", int(index)//int(n), \"processed. Data from\", int(index), \"rows saved to journal_issn.json mapping file\")\n",
    "                    issn_data_to_cache(journal_issn_dict, output_dir)\n",
    "\n",
    "                citing_pmid = pmid_manager.normalise(row['pmid'], True)\n",
    "                pmid_manager.set_valid(citing_pmid)\n",
    "                citing_doi = doi_manager.normalise(row['doi'], True)\n",
    "\n",
    "                if id_date.get_value(citing_pmid) is None:\n",
    "                    citing_date = Citation.check_date(build_pubdate(row))\n",
    "                    if citing_date is not None:\n",
    "                        id_date.add_value(citing_pmid, citing_date)\n",
    "                        if citing_pmid in citing_pmid_with_no_date:\n",
    "                            citing_pmid_with_no_date.remove(citing_pmid)\n",
    "                    else:\n",
    "                        citing_pmid_with_no_date.add( citing_pmid )\n",
    "\n",
    "                if id_issn.get_value( citing_pmid ) is None:\n",
    "                    journal_name = row[\"journal\"]\n",
    "                    if journal_name: #check that the string is not empty\n",
    "                        if journal_name in journal_issn_dict.keys():\n",
    "                            for issn in journal_issn_dict[journal_name]:\n",
    "                                id_issn.add_value(citing_pmid, issn)\n",
    "                        else:\n",
    "                            if citing_doi is not None:\n",
    "                                json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                if json_res is not None:\n",
    "                                    issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                    if len(issn_set)>0:\n",
    "                                        journal_issn_dict[journal_name] = []\n",
    "                                    for issn in issn_set:\n",
    "                                        issn_norm = issn_manager.normalise(str(issn))\n",
    "                                        id_issn.add_value( citing_pmid, issn_norm )\n",
    "                                        journal_issn_dict[journal_name].append(issn_norm)\n",
    "\n",
    "\n",
    "                if id_orcid.get_value(citing_pmid) is None:\n",
    "                    if citing_doi is not None:\n",
    "                        json_res = orcid_resource_finder._call_api(citing_doi)\n",
    "                        if json_res is not None:\n",
    "                            orcid_set = orcid_resource_finder._get_orcid(json_res)\n",
    "                            for orcid in orcid_set:\n",
    "                                orcid_norm = orcid_manager.normalise( orcid )\n",
    "                                id_orcid.add_value(citing_pmid, orcid_norm)\n",
    "\n",
    "            issn_data_to_cache( journal_issn_dict, output_dir )\n",
    "\n",
    "\n",
    "    # Iterate once again for all the rows of all the csv files, so to check the validity of the referenced pmids.\n",
    "    print( \"\\n\\n# Checking the referenced pmids validity\" )\n",
    "    for file_idx, file in enumerate( all_files, 1 ):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv( file, chunksize=1000 ):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            print( \"Open file %s of %s\" % (file_idx, len_all_files) )\n",
    "            for index, row in f.iterrows():\n",
    "                if row[\"references\"] != \"\":\n",
    "                    ref_string = row[\"references\"].strip()\n",
    "                    ref_string_norm = re.sub(\"\\s+\", \" \", ref_string)\n",
    "                else:\n",
    "                    print(\"the type of row reference is\", (row[\"references\"]), type(row[\"references\"]))\n",
    "                    print(index, row )\n",
    "\n",
    "                cited_pmids = set(ref_string_norm.split(\" \"))\n",
    "                for cited_pmid in cited_pmids:\n",
    "                    if pmid_manager.is_valid(cited_pmid):\n",
    "                        print(\"valid cited pmid added:\", cited_pmid)\n",
    "                    else:\n",
    "                        print(\"invalid cited pmid discarded:\", cited_pmid)\n",
    "\n",
    "    for pmid in citing_pmid_with_no_date:\n",
    "        id_date.add_value( pmid, \"\" )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    arg_parser = ArgumentParser( \"Global files creator for NOCI\",\n",
    "                                 description=\"Process NIH CSV files and create global indexes to enable \"\n",
    "                                             \"the creation of NOCI.\" )\n",
    "    arg_parser.add_argument( \"-i\", \"--input_dir\", dest=\"input_dir\", required=True,\n",
    "                             help=\"Either the directory or the zip file that contains the NIH data dump \"\n",
    "                                  \"of CSV files.\" )\n",
    "    arg_parser.add_argument( \"-o\", \"--output_dir\", dest=\"output_dir\", required=True,\n",
    "                             help=\"The directory where the indexes are stored.\" )\n",
    "\n",
    "\n",
    "    arg_parser.add_argument( \"-n\", \"--num_lines\", dest=\"n\", required=True,\n",
    "                             help=\"Number of lines after which the data stored in the dictionary for the mapping \"\n",
    "                                  \"between a Journal name and the related issns are passed into a JSON cache file\" )\n",
    "\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "\n",
    "    start = timer()\n",
    "    process(args.input_dir, args.output_dir, args.n)\n",
    "    end = timer()\n",
    "    #calculate elapsed time\n",
    "    print(\"elapsed time, in seconds:\", (end-start))\n",
    "\n",
    "\n",
    "#python -m index.noci.glob1 -i \"index/test_data/nih_dump\" -o \"index/test_data/nih_glob1\" -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/13_glob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from os import sep, remove\n",
    "import os\n",
    "from os.path import exists\n",
    "from index.noci.glob1 import issn_data_recover, issn_data_to_cache, build_pubdate, get_all_files, process\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from index.identifier.pmidmanager import PMIDManager\n",
    "from index.identifier.doimanager import DOIManager\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "class MyTestCase( unittest.TestCase ):\n",
    "    def setUp(self):\n",
    "        self.dir_with_issn_map = \"index%stest_data%sglob_noci%sissn_data_recover%swith_issn_mapping\" % (sep, sep, sep, sep)\n",
    "        self.dir_without_issn_map = \"index%stest_data%sglob_noci%sissn_data_recover%swithout_issn_mapping\" % (sep, sep, sep, sep)\n",
    "        self.issn_journal_sample_dict = {\"N Biotechnol\": [\"1871-6784\"], \"Biochem Med\": [\"0006-2944\"], \"Magn Reson Chem\": [\"0749-1581\"]}\n",
    "        self.data_to_cache_dir = \"index%stest_data%sglob_noci%sissn_data_to_cache\" % (sep, sep, sep)\n",
    "        self.get_all_files_dir = \"index%stest_data%sglob_noci%sget_all_files\" % (sep, sep, sep)\n",
    "        self.csv_sample = \"index%stest_data%sglob_noci%sget_all_files%s1.csv\" % (sep, sep, sep, sep)\n",
    "        self.output_dir = \"index%stest_data%sglob_noci%sprocess%soutput\" % (sep, sep, sep, sep)\n",
    "        self.valid_pmid = CSVManager( self.output_dir + sep + \"valid_pmid.csv\" )\n",
    "        self.valid_doi = CSVManager( \"index/test_data/crossref_glob\" + sep + \"valid_doi.csv\" )\n",
    "        self.id_date = CSVManager( self.output_dir + sep + \"id_date_pmid.csv\" )\n",
    "        self.id_issn = CSVManager( self.output_dir + sep + \"id_issn_pmid.csv\" )\n",
    "        self.id_orcid = CSVManager( self.output_dir + sep + \"id_orcid_pmid.csv\" )\n",
    "        self.doi_manager = DOIManager(self.valid_doi)\n",
    "        self.pmid_manager = PMIDManager(self.valid_pmid)\n",
    "        self.issn_manager = ISSNManager()\n",
    "        self.orcid_manager = ORCIDManager()\n",
    "        self.sample_reference = \"pmid:7829625\"\n",
    "\n",
    "    def test_issn_data_recover(self):\n",
    "        #Test the case in which there is no mapping file for journals - issn\n",
    "        self.assertEqual(issn_data_recover(self.dir_without_issn_map), {})\n",
    "        #Test the case in which there is a mapping file for journals - issn\n",
    "        issn_map_dict_len = len(issn_data_recover(self.dir_with_issn_map))\n",
    "        self.assertTrue(issn_map_dict_len>0)\n",
    "\n",
    "    def test_issn_data_to_cache(self):\n",
    "        filename = self.data_to_cache_dir + sep + 'journal_issn.json'\n",
    "        if exists(filename):\n",
    "            remove(filename)\n",
    "        self.assertFalse(exists(filename))\n",
    "        issn_data_to_cache(self.issn_journal_sample_dict, self.data_to_cache_dir)\n",
    "        self.assertTrue(exists(filename))\n",
    "\n",
    "    def test_get_all_files(self):\n",
    "        all_files, opener = get_all_files( self.get_all_files_dir)\n",
    "        len_all_files = len(all_files)\n",
    "        #The folder contains 4 csv files, but two of those contains the words \"citations\" or \"source\" in their filenames\n",
    "        self.assertEqual( len_all_files, 2)\n",
    "\n",
    "    def test_build_pubdate(self):\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv(self.csv_sample, chunksize=1000):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna( \"\", inplace=True )\n",
    "            for index, row in f.iterrows():\n",
    "                pub_date = build_pubdate(row)\n",
    "                self.assertTrue(isinstance(pub_date, str))\n",
    "                self.assertTrue(isinstance(int(pub_date), int))\n",
    "                self.assertEqual(len(pub_date), 4)\n",
    "\n",
    "    def test_process(self):\n",
    "        for files in os.listdir( self.output_dir):\n",
    "            path = os.path.join( self.output_dir, files )\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        self.assertEqual(len(os.listdir(self.output_dir)),0)\n",
    "        process(self.get_all_files_dir, self.output_dir, 20)\n",
    "        self.assertTrue(len(os.listdir(self.output_dir))>0)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv( self.csv_sample, chunksize=1000 ):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna( \"\", inplace=True )\n",
    "            for index, row in f.iterrows():\n",
    "                if index == 1:\n",
    "                    pmid = row[\"pmid\"]\n",
    "\n",
    "        citing_pmid = self.pmid_manager.normalise(pmid, include_prefix=True)\n",
    "\n",
    "        self.assertEqual(self.valid_pmid.get_value(citing_pmid), {'v'})\n",
    "        self.assertEqual(self.valid_pmid.get_value(self.sample_reference), {'v'})\n",
    "        self.assertEqual(self.id_date.get_value(citing_pmid), {'1998'})\n",
    "        self.assertEqual(self.id_issn.get_value(citing_pmid), {'0918-8959', '1348-4540'})\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv( self.csv_sample, chunksize=1000 ):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna( \"\", inplace=True )\n",
    "            for index, row in f.iterrows():\n",
    "                if index == 0:\n",
    "                    pmid = row[\"pmid\"]\n",
    "\n",
    "        citing_pmid = self.pmid_manager.normalise(pmid, include_prefix=True)\n",
    "\n",
    "        self.assertEqual(self.id_orcid.get_value(citing_pmid), {'0000-0002-0524-4077'})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "\n",
    "#python -m unittest index.test.13_glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 PMID manager <a class=\"anchor\" id=\"en_1.1.3\"></a>\n",
    "La classe PMIDManager è sviluppata come **istanza della superclasse IdentifierManager**. Lo sviluppo del PMIDManager è modellato sull'esempio della classe DOIManager, con cui condivide scopo e funzioni.\n",
    "In particolare, gli identifier manager si occupano di normalizzare il formato degli identificativi, per poi verificarne l'esistenza e la validità ricorrendo a servizi di API specifici per ogni tipo di identificativo.\n",
    "L'**API service** utilizzato per i PMID è **https://pubmed.ncbi.nlm.nih.gov/**, che fornisce in risposta una **pagina HTML**. Per questo motivo, l'informazione relativa all'avvenuta o mancata validazione del PMID in questione viene estratta con gli strumenti forniti dalla libreria **BeautifulSoup**. \n",
    "Di seguito, il codice del PMID manager e l'estensione del test case per gli identifier managers. Il test è stato passato con successo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.identifier.identifiermanager import IdentifierManager\n",
    "from re import sub, match\n",
    "from urllib.parse import unquote, quote\n",
    "from requests import get\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from requests import ReadTimeout\n",
    "from requests.exceptions import ConnectionError\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "class PMIDManager( IdentifierManager ):\n",
    "    def __init__(self, valid_pmid=None, use_api_service=True):\n",
    "        if valid_pmid is None:\n",
    "            valid_pmid = CSVManager( store_new=False )\n",
    "\n",
    "        self.api = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "        self.valid_pmid = valid_pmid\n",
    "        self.use_api_service = use_api_service\n",
    "        self.p = \"pmid:\"\n",
    "        super( PMIDManager, self ).__init__()\n",
    "\n",
    "    def set_valid(self, id_string):\n",
    "        pmid = self.normalise(id_string, include_prefix=True )\n",
    "        if self.valid_pmid.get_value( pmid ) is None:\n",
    "            self.valid_pmid.add_value( pmid, \"v\" )\n",
    "\n",
    "    def is_valid(self, id_string):\n",
    "        pmid = self.normalise( id_string, include_prefix=True )\n",
    "        if pmid is None or match( \"^pmid:[1-9]\\d*$\", pmid ) is None:\n",
    "            return False\n",
    "        else:\n",
    "            if self.valid_pmid.get_value( pmid ) is None:\n",
    "                if self.__pmid_exists( pmid ):\n",
    "                    self.valid_pmid.add_value( pmid, \"v\" )\n",
    "                else:\n",
    "                    self.valid_pmid.add_value( pmid, \"i\" )\n",
    "            return \"v\" in self.valid_pmid.get_value( pmid )\n",
    "\n",
    "    def normalise(self, id_string, include_prefix=False):\n",
    "        id_string = str(id_string)\n",
    "        try:\n",
    "            pmid_string = sub( \"^0+\", \"\", sub( \"\\0+\", \"\", (sub( \"[^\\d+]\", \"\", id_string )) ) )\n",
    "            return \"%s%s\" % (self.p if include_prefix else \"\", pmid_string)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def __pmid_exists(self, pmid_full):\n",
    "        pmid = self.normalise( pmid_full )\n",
    "        if self.use_api_service:\n",
    "            tentative = 3\n",
    "            while tentative:\n",
    "                tentative -= 1\n",
    "                try:\n",
    "                    r = get( self.api + quote( pmid ) + \"/?format=pmid\", headers=self.headers, timeout=30 )\n",
    "                    if r.status_code == 200:\n",
    "                        r.encoding = \"utf-8\"\n",
    "\n",
    "                        soup = BeautifulSoup( r.content, features=\"lxml\" )\n",
    "                        for i in soup.find_all( \"meta\", {\"name\": \"uid\"} ):\n",
    "                            id = i[\"content\"]\n",
    "                            if id == pmid:\n",
    "                                return True\n",
    "\n",
    "                except ReadTimeout:\n",
    "                    pass\n",
    "                except ConnectionError:\n",
    "                    sleep(5)\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/02_identifiermanager.py (PMID extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from os import sep\n",
    "from index.identifier.doimanager import DOIManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from index.identifier.pmidmanager import PMIDManager\n",
    "from index.storer.csvmanager import CSVManager\n",
    "\n",
    "\n",
    "class IdentifierManagerTest(unittest.TestCase):\n",
    "    \"\"\"This class aim at testing the methods of the class CSVManager.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "#[...]\n",
    "\n",
    "#class extension for pubmedid\n",
    "        self.valid_pmid_1 = \"2942070\"\n",
    "        self.valid_pmid_2 = \"1509982\"\n",
    "        self.valid_pmid_3 = \"7189714\"\n",
    "        self.invalid_pmid_1 = \"0067308798798\"\n",
    "        self.invalid_pmid_2 = \"pmid:174777777777\"\n",
    "        self.invalid_pmid_3 = \"000009265465465465\"\n",
    "        self.valid_pmid_path = \"index%stest_data%svalid_pmid.csv\" % (sep, sep)\n",
    "\n",
    "#[...]\n",
    "\n",
    "#class extension for pubmedid\n",
    "    def test_pmid_normalise(self):\n",
    "        pm = PMIDManager()\n",
    "        self.assertEqual(self.valid_pmid_1, pm.normalise(self.valid_pmid_1.replace(\"\", \"pmid:\")))\n",
    "        self.assertEqual(self.valid_pmid_1, pm.normalise(self.valid_pmid_1.replace(\"\", \" \")))\n",
    "        self.assertEqual(self.valid_pmid_1, pm.normalise(\"https://pubmed.ncbi.nlm.nih.gov/\"+self.valid_pmid_1))\n",
    "        self.assertEqual(self.valid_pmid_2, pm.normalise(\"000\"+self.valid_pmid_2))\n",
    "\n",
    "    def test_pmid_is_valid(self):\n",
    "        pm_nofile = PMIDManager()\n",
    "        print(pm_nofile.normalise(self.valid_pmid_1, include_prefix=True ))\n",
    "        print(pm_nofile.is_valid(self.valid_pmid_1))\n",
    "        self.assertTrue(pm_nofile.is_valid(self.valid_pmid_1))\n",
    "        self.assertTrue(pm_nofile.is_valid(self.valid_pmid_2))\n",
    "        self.assertTrue(pm_nofile.is_valid(self.valid_pmid_3))\n",
    "        self.assertFalse(pm_nofile.is_valid(self.invalid_pmid_1))\n",
    "        self.assertFalse(pm_nofile.is_valid(self.invalid_pmid_2))\n",
    "        self.assertFalse(pm_nofile.is_valid(self.invalid_pmid_3))\n",
    "\n",
    "        valid_pmid = CSVManager(self.valid_pmid_path)\n",
    "        pm_file = PMIDManager(valid_pmid=valid_pmid, use_api_service=False)\n",
    "        self.assertTrue(pm_file.is_valid(self.valid_pmid_1))\n",
    "        self.assertFalse(pm_file.is_valid(self.invalid_pmid_1))\n",
    "\n",
    "        pm_nofile_noapi = PMIDManager(use_api_service=False)\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.valid_pmid_1))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.invalid_pmid_1))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.valid_pmid_2))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.invalid_pmid_2))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.valid_pmid_3))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.invalid_pmid_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 NIH resource finder <a class=\"anchor\" id=\"en_1.1.4\"></a>\n",
    "La classe NIHResourceFinder è sviluppata come **istanza della superclasse ApiIDResourceFinder** e il suo scopo è quello di **recuperare metadati dall'API per i PMID**, nel caso in cui nel processo non vengano forniti files di supporto generati nel preprocessing dal glob di NOCI. \n",
    "Il servizio utilizzato è https://pubmed.ncbi.nlm.nih.gov/ (con display option \"pubmed\") che restituisce risposte in formato HTML. Per questo motivo, i dati sono estratti utilizzando la libreria **Beautiful Soup** per accedere alla sezione che contiene la stringa testuale con i metadati. A questo punto, i dati sono estratti dalla stringa testuale sfruttando le **regex**. \n",
    "A differenza dei servizi API per i DOI, questa REST API non fornisce dati particolarmente dettagliati e non copre alcune delle informazioni richieste dall'OCDM, come ad esempio gli ORCID degli autori. Tra i metadati a disposizione, gli unici utili sono la **data di pubblicazione** e l'**ISSN** della rivista di pubblicazione. \n",
    "Di seguito, lo script del NIHResourceFinder e la relativa espansionsione del testcase 03_resourcefinder.py. Il test è stato superato con successo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.finder.resourcefinder import ApiIDResourceFinder\n",
    "from index.citation.oci import OCIManager\n",
    "from requests import get\n",
    "from urllib.parse import quote\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "class NIHResourceFinder(ApiIDResourceFinder):\n",
    "    def __init__(self, date=None, orcid=None, issn=None, pmid=None, use_api_service=True):\n",
    "        self.use_api_service = use_api_service\n",
    "        self.api = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "        self.baseurl = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "        super(NIHResourceFinder, self).__init__(date=date, orcid=orcid, issn=issn, id=pmid, id_type=OCIManager.pmid_type,\n",
    "                                                     use_api_service=use_api_service)\n",
    "\n",
    "    def _get_issn(self, txt_obj):\n",
    "        result = set()\n",
    "        issns = re.findall(\"IS\\s+-\\s+\\d{4}-\\d{4}\", txt_obj)\n",
    "        for i in issns:\n",
    "            issn = re.search(\"\\d{4}-\\d{4}\", i).group(0)\n",
    "            result.add(issn)\n",
    "        return result\n",
    "\n",
    "    def _get_date(self, txt_obj):\n",
    "        date = re.search(\"DP\\s+-\\s+(\\d{4}(\\s?(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))?(\\s?((3[0-1])|([1-2][0-9])|([0]?[1-9])))?)\", txt_obj).group(1)\n",
    "        re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+((3[0-1])|([1-2][0-9])|([0]?[1-9]))\", date)\n",
    "        if re_search is not None:\n",
    "            result = re_search.group(0)\n",
    "            datetime_object = datetime.strptime(result, '%Y %b %d')\n",
    "            return datetime.strftime(datetime_object, '%Y-%m-%d')\n",
    "        else:\n",
    "            re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\", date)\n",
    "            if re_search is not None:\n",
    "                result = re_search.group(0)\n",
    "                datetime_object = datetime.strptime(result, '%Y %b')\n",
    "                return datetime.strftime(datetime_object, '%Y-%m')\n",
    "            else:\n",
    "                re_search = re.search(\"(\\d{4})\", date)\n",
    "                if re_search is not None:\n",
    "                    result = re.search(\"(\\d{4})\", date).group(0)\n",
    "                    datetime_object = datetime.strptime(result, '%Y')\n",
    "                    return datetime.strftime(datetime_object, '%Y')\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "\n",
    "    def _call_api(self, pmid_full):\n",
    "        if self.use_api_service:\n",
    "            pmid = self.pm.normalise(pmid_full)\n",
    "            r = get(self.api + quote(pmid) + \"/?format=pubmed\", headers=self.headers, timeout=30)\n",
    "            if r.status_code == 200:\n",
    "                r.encoding = \"utf-8\"\n",
    "                soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "                mdata = str(soup.find(id=\"article-details\"))\n",
    "                return mdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/03_resourcefinder.py (PMID extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from os import sep\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from index.finder.crossrefresourcefinder import CrossrefResourceFinder\n",
    "from index.finder.dataciteresourcefinder import DataCiteResourceFinder\n",
    "from index.finder.nihresourcefinder import NIHResourceFinder\n",
    "from index.finder.orcidresourcefinder import ORCIDResourceFinder\n",
    "from index.finder.resourcefinder import ResourceFinderHandler\n",
    "\n",
    "\n",
    "class ResourceFinderTest(unittest.TestCase):\n",
    "    \"\"\"This class aim at testing the methods of the class CSVManager.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        self.date_path = \"index%stest_data%sid_date.csv\" % (sep, sep)\n",
    "        self.date_path_pmid = \"index%stest_data%sid_date_pmid.csv\" % (sep, sep)\n",
    "        self.orcid_path = \"index%stest_data%sid_orcid.csv\" % (sep, sep)\n",
    "        self.orcid_path_pmid = \"index%stest_data%sid_orcid_pmid.csv\" % (sep, sep)\n",
    "        self.issn_path = \"index%stest_data%sid_issn.csv\" % (sep, sep)\n",
    "        self.issn_path_pmid = \"index%stest_data%sid_issn_pmid.csv\" % (sep, sep)\n",
    "        self.doi_path = \"index%stest_data%svalid_doi.csv\" % (sep, sep)\n",
    "        self.pmid_path = \"index%stest_data%svalid_pmid.csv\" % (sep, sep)\n",
    "#[...]\n",
    "    \n",
    "    def test_nationalinstititeofhealth_get_orcid(self):\n",
    "        #Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertIsNone(nf_1.get_orcid(\"7189714\"))\n",
    "        self.assertIsNone(nf_1.get_orcid(\"1509982\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        nf_2 = NIHResourceFinder(orcid=CSVManager(self.orcid_path_pmid),\n",
    "                                      pmid=CSVManager(self.pmid_path), use_api_service=False)\n",
    "        self.assertIn(\"0000-0002-1825-0097\", nf_2.get_orcid(\"7189714\"))\n",
    "        self.assertNotIn(\"0000-0002-1825-0098\", nf_2.get_orcid(\"1509982\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_orcid(\"7189714\"))\n",
    "\n",
    "    def test_nationalinstititeofhealth_get_issn(self):\n",
    "        # Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertIn(\"0003-4819\", nf_1.get_container_issn(\"2942070\"))\n",
    "        self.assertNotIn(\"0003-0000\", nf_1.get_container_issn(\"2942070\"))\n",
    "\n",
    "        # # Do use support files, but avoid using APIs\n",
    "        nf_2 = NIHResourceFinder(issn=CSVManager(self.issn_path_pmid),\n",
    "                                      pmid=CSVManager(self.pmid_path), use_api_service=False)\n",
    "        container = nf_2.get_container_issn(\"1509982\")\n",
    "        self.assertIn(\"0065-4299\", container)\n",
    "        self.assertNotIn(\"0065-4444\", nf_2.get_container_issn(\"1509982\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_container_issn(\"7189714\"))\n",
    "\n",
    "    def test_nationalinstititeofhealth_get_pub_date(self):\n",
    "        # Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertIn(\"1998-05-25\", nf_1.get_pub_date(\"9689714\"))\n",
    "        self.assertNotEqual(\"1998\", nf_1.get_pub_date(\"9689714\"))\n",
    "\n",
    "        # Do not use support files, only APIs\n",
    "        nf_2 = NIHResourceFinder(date=CSVManager(self.date_path_pmid),\n",
    "                                      pmid=CSVManager(self.pmid_path), use_api_service=False)\n",
    "        self.assertIn(\"1980-06\", nf_2.get_pub_date(\"7189714\"))\n",
    "        self.assertNotEqual(\"1980-06-22\", nf_2.get_pub_date(\"7189714\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_pub_date(\"2942070\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 citation/oci.py <a class=\"anchor\" id=\"en_1.2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 finder/resourcefinder.py <a class=\"anchor\" id=\"en_1.2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 finder/dataciteresourcefinder.py <a class=\"anchor\" id=\"en_1.2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 finder/crossrefresourcefinder.pyr <a class=\"anchor\" id=\"en_1.2.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 finder/orcidresourcefinder.py <a class=\"anchor\" id=\"en_1.2.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 storer/csvmanager.py <a class=\"anchor\" id=\"en_1.2.6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 storer/datahandler.py <a class=\"anchor\" id=\"en_1.2.7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.8 storer/update.py <a class=\"anchor\" id=\"en_1.2.8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAMOSE - NOCI configuration file<a class=\"anchor\" id=\"en_2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAMOSE - indexapi.py <a class=\"anchor\" id=\"en_2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09/03 - 15/03 (Log Data Visualization d3.js) <a class=\"anchor\" id=\"entry_3\"></a>\n",
    "\n",
    "Lorem Ipsum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15/03 - 22/03 (????) <a class=\"anchor\" id=\"entry_4\"></a>\n",
    "\n",
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ??/?? - ??/?? (????) <a class=\"anchor\" id=\"entry_5\"></a>\n",
    "????????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
